{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from sharknado.scipy.lib.data_manipulation import shark\n",
    "from sharknado.scipy.transformers import signature\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "from IPython.display import clear_output\n",
    "from seaborn import plt\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data_dir = os.path.join(os.path.dirname(os.getcwd()), \"data\", \"raw\")\n",
    "schemas = joblib.load(os.path.join(raw_data_dir, \"schemas.dat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_dir = os.path.join(os.path.dirname(os.getcwd()), \"references\")\n",
    "with open(os.path.join(ref_dir, \"rare_merchants.txt\"), \"r\") as f:\n",
    "    merchants = np.array([line.strip() for line in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neural_merchant_scrubbing.src.models import hash_net as hn\n",
    "from neural_merchant_scrubbing.src.features import build_features as bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(hn)\n",
    "trainer, encoder = hn.build_triplet_encoder(\n",
    "    52, 125,\n",
    "    encoder_fn=hn.dense_encoder,\n",
    "    dist_fn=hn.tanh_hammingoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         input_70         (None, 125) -> (None, 125)\n",
      "       embedding_26       (None, 125) -> (None, 125, 32)\n",
      "     convolution1d_91     (None, 125, 32) -> (None, 125, 64)\n",
      "     convolution1d_92     (None, 125, 32) -> (None, 125, 64)\n",
      "        merge_102         [(None, 125, 64), (None, 125, 64)] -> (None, 125, 128)\n",
      "      leakyrelu_107       (None, 125, 128) -> (None, 125, 128)\n",
      "  globalmaxpooling1d_46   (None, 125, 128) -> (None, 128)\n",
      "         dense_38         (None, 128) -> (None, 128)\n",
      "      leakyrelu_108       (None, 128) -> (None, 128)\n",
      "         dense_39         (None, 128) -> (None, 32)\n",
      "        reshape_52        (None, 32) -> (None, 32, 1)\n",
      "  binaryencoderlayer_17   (None, 32, 1) -> (None, 32)\n"
     ]
    }
   ],
   "source": [
    "for l in encoder.layers:\n",
    "    print l.name.center(25), l.input_shape, \"->\", l.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = bf.CharacterVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "PUNCT = re.compile(r\"[:/.@*`'-]\")\n",
    "SPACE = re.compile(r\" {2,}\")\n",
    "\n",
    "def permute_merchant(m):\n",
    "    # 10% of the time, drop the last word of a merchant w/ 3+ words\n",
    "    if len(m.split()) > 2 and np.random.random() < 0.1:\n",
    "        m = \" \".join(m.split()[:-1])\n",
    "    # 20% of the time, strip up to 5 characters off the end\n",
    "    if np.random.random() < 0.2:\n",
    "        m = m[:-np.random.randint(1, 6)].strip()\n",
    "    # 10% of the time, remove all saces\n",
    "    if np.random.random() < 0.1:\n",
    "        replacer = \"\" if np.random.random() < 0.5 else \" \"\n",
    "        m = SPACE.sub(\" \", PUNCT.sub(replacer, m))\n",
    "    return m\n",
    "\n",
    "def batch_generator(batch_size, schemas, merchants, cv):\n",
    "    schm_cursor = 0\n",
    "    schm_size = schemas.shape[0]\n",
    "    schm_ixs = np.arange(schm_size)\n",
    "    mrch_cursor = 0\n",
    "    mrch_size = merchants.shape[0]\n",
    "    mrch_ixs = np.arange(mrch_size)\n",
    "    while True:\n",
    "        \n",
    "        if schm_cursor + (3 * batch_size) >= schm_size:\n",
    "            schm_cursor = 0\n",
    "        if schm_cursor == 0:\n",
    "            np.random.shuffle(schm_ixs)\n",
    "        \n",
    "        if mrch_cursor + (2 * batch_size) >= mrch_size:\n",
    "            mrch_cursor = 0\n",
    "        if mrch_cursor == 0:\n",
    "            np.random.shuffle(mrch_ixs)\n",
    "        \n",
    "        batch_merchants = merchants[mrch_ixs[mrch_cursor:mrch_cursor + (2 * batch_size)]]\n",
    "        x_m = [permute_merchant(m) for m in batch_merchants[:batch_size]]\n",
    "        y_m = [permute_merchant(m) for m in batch_merchants[:batch_size]]\n",
    "        z_m = [permute_merchant(m) for m in batch_merchants[batch_size:]]\n",
    "\n",
    "        batch_schemas = schemas[schm_ixs[schm_cursor:schm_cursor + (3 * batch_size)]]\n",
    "        x_s, y_s, z_s = batch_schemas.reshape((3, batch_size))\n",
    "\n",
    "        x_ms = [s.replace(\"_____\", m) for m, s in zip(x_m, x_s)]\n",
    "        y_ms = [s.replace(\"_____\", m) for m, s in zip(y_m, y_s)]\n",
    "        z_ms = [s.replace(\"_____\", m) for m, s in zip(z_m, z_s)]\n",
    "        \n",
    "        yield (\n",
    "            [cv.transform(ar).toarray() for ar in (x_ms, y_ms, z_ms)],\n",
    "            np.zeros(batch_size))\n",
    "        schm_cursor += 3 * batch_size\n",
    "        mrch_cursor += 2 * batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema_ixs = np.arange(schemas.shape[0])\n",
    "np.random.shuffle(schema_ixs)\n",
    "schema_test = schemas[schema_ixs[:1000]]\n",
    "schema_train = schemas[schema_ixs[1000:]]\n",
    "\n",
    "merch_ixs = np.arange(merchants.shape[0])\n",
    "np.random.shuffle(merch_ixs)\n",
    "merch_test = merchants[merch_ixs[:1000]]\n",
    "merch_train = merchants[merch_ixs[1000:]]\n",
    "\n",
    "train_gen = batch_generator(32, schema_train, merch_train, cv)\n",
    "test_gen = batch_generator(32, schema_test, merch_test, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.compile(optimizer=\"adam\", loss=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32000/32000 [==============================] - 179s - loss: 0.3133 - val_loss: 0.2843\n",
      "Epoch 2/5\n",
      "32000/32000 [==============================] - 170s - loss: 0.2798 - val_loss: 0.2652\n",
      "Epoch 3/5\n",
      "32000/32000 [==============================] - 175s - loss: 0.2591 - val_loss: 0.2448\n",
      "Epoch 4/5\n",
      "32000/32000 [==============================] - 168s - loss: 0.2510 - val_loss: 0.2549\n",
      "Epoch 5/5\n",
      "32000/32000 [==============================] - 174s - loss: 0.2522 - val_loss: 0.2351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x131438490>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit_generator(\n",
    "    train_gen,\n",
    "    samples_per_epoch=32 * 1000,\n",
    "    nb_epoch=5,\n",
    "    verbose=1,\n",
    "    validation_data=test_gen,\n",
    "    nb_val_samples=32 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.], dtype=float32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict([ar.reshape(1, 125) for ar in cv.transform([\n",
    "    \"CHECKCARD 0913 MCDONALD'S #13156 LINDEN NJ 24231684257206988001017\",\n",
    "    \"MCDONALDS 10/28\",\n",
    "    \"JAVA ON FOUR\"]).toarray()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = encoder.predict(cv.transform([\n",
    "    \"CHECKCARD 0913 MCDONALDS #13156 LINDEN NJ 24231684257206988001017\",\n",
    "    \"POS PIN MCDONALDS\",\n",
    "    \"Wendy's\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0] == preds[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}